# AI/ML Microservice

## Purpose
- Local LLM inference and compliance AI assistant
- No cloud dependency (Saudi regulatory compliance)
- Extensible for future AI/ML features (risk prediction, Q&A, etc.)

## Features
- RESTful API for LLM-based Q&A and compliance support
- Pluggable model support (HuggingFace, llama.cpp, etc.)
- Designed for on-prem, secure, and resource-aware operation

## Roadmap
- Phase 1: API skeleton, config, and health endpoints
- Phase 2: Local LLM inference and Q&A
- Phase 3: Advanced AI/ML features (risk, prediction, analytics)

---
See the root and microservices README for architecture and deployment details.
